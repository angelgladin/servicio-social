\documentclass[xcolor=dvipsnames]{beamer}
%\documentclass[xcolor=dvipsnames,handout]{beamer}

\input{macros2006}

\newcommand{\titulos}[2]{\frametitle{#1}\framesubtitle{#2}}
\newcommand{\espc}{\vspace{.5cm}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\cv}{\ensuremath{\varepsilon}}
\newcommand{\sest}{\ensuremath{\Sigma^\star}}
\newtheorem{teorema}{Teorema}
\renewcommand{\S}{\Sigma}
\newcommand{\de}{\delta}
\newcommand{\izq}{\leftarrow}
\newcommand{\der}{\rightarrow}
\newcommand{\dest}{\ensuremath{\delta^\star}}


\mode<presentation>
{
\usetheme[secheader]{Boadilla}
%\useinnertheme{rounded}
\useoutertheme{infolines}
%\usepackage{BeamerColor}
%\usecolortheme[RGB={33,66,33}]{structure}
\usecolortheme[named=NavyBlue]{structure}
%\usefonttheme{}
\setbeamercovered{invisible}
%\setbeamertemplate{headline}{\insertshortinstitute}
%\setbeamertemplate{footline}[page number]{\insertshortinstitute}
%\insertshortinstitute
}

\usepackage[spanish]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}


\title[AyLF]{Autómatas y Lenguajes Formales}
\subtitle
{%Maestría en Ciencia e Ingeniería de la Computación UNAM\\
  Lenguajes de Dyck y el Teorema de Chomsky-Schuetzenberger}

\author[Favio E. Miranda Perea]{Dr. Favio Ezequiel Miranda Perea \\ \texttt{favio@ciencias.unam.mx}}


\institute[FC UNAM]{Facultad de Ciencias UNAM\footnote{Con el apoyo del proyecto PAPIME PE102117}}

\date{\today}

\subject{Theoretical Computer Science}

% \pgfdeclareimage[height=0.5cm]{LogoTecBueno}{LogoTecBueno.eps}
\logo{\includegraphics[height=1cm]{fc2.png}}




\begin{document}

\beamerdefaultoverlayspecification{<+->}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \titulos{Homomorfismos de lenguajes}{}
\bi
\item Sean $\Sigma,\Delta$ dos alfabetos. Una función $h:\Sigma^\star\to\Delta^\star$ es un homomorfismo si y sólo si
\bi
\item $h(\varepsilon)=\varepsilon$
\item $h(xy)=h(x)h(y)$
\ei
\medskip
\item Un homomorfismo $h$ queda determinado de manera única por sus valores en $\Sigma$. \medskip
\item Más aún, cualquier función $f:\Sigma\to\Delta^\star$ puede extenderse de manera única a un homomorfismo $h:\Sigma^\star\to\Delta^\star$ tal que 
si $x\in\Sigma$ entonces $h(x)=f(x)$. Este homomorfismo se define como:
\[
h(s_1s_2\ldots s_n) =_{def} f(s_1)f(s_2)\ldots f(s_n)
\]
para cada $s_i\in\Sigma$
\ei



\end{frame}



\begin{frame}
  \titulos{Imágen e imagen inversa de una función}{}
Dados una función $f:A\to B$, $X\subseteq A$ y $Y\subseteq B$, definimos:
\begin{itemize}
\item La imagen de $X$ bajo $f$, denotada $f[X]$, como
\[
f[X]=\{f(x)\mid x\in A\}
\]
 \medskip
\item La imagen inversa de $Y$ bajo $f$, denotada $f^{-1}[Y]$, como
\[
f^{-1}[Y]=\{x\mid f(x)\in Y\}
\]
 \medskip
\item Obsérvese que $f[X]\subseteq B$ y $f^{-1}[Y]\subseteq A$ \medskip
\item Propiedad relevante: $f[X\cup Z] = f[X]\cup f[Z]$
\end{itemize}
\end{frame}


\begin{frame}
  \titulos{Propiedades de cerradura}{Homomorfismos de lenguajes}

Sean $h:\Sigma^\star\to\Delta^\star, L\subseteq \Sigma^\star, S\subseteq\Delta^\star$.
  \begin{itemize}
 
  \item Si $L$ es regular entonces $h[L]$ es regular. Es decir, la imagen de un lenguaje regular bajo un homomorfismo es regular. \medskip
   \item Si $S$ es regular entonces $h^{-1}[S]$ es regular. Es decir, la imagen inversa de un lenguaje regular bajo un homomorfismo es regular. \medskip
     \item Si $L$ es libre de contexto entonces $h[L]$ es libre de contexto. Es decir, la imagen de un lenguaje libre de contexto bajo un homomorfismo es libre de contexto. \medskip
\item Propiedad de cerradura importante: Si $R$ es regular y $L$ es libre de contexto entonces $R\cap L$ es libre de contexto.
  \end{itemize}

\end{frame}


% \begin{frame}
%   \titulos{Morfismo de Thue-Morse}{}
% \end{frame}


\begin{frame}
  \titulos{Homomorfismos de borrado}{}
\bi
\item Sean $\Sigma,B$ dos alfabetos ajenos, es decir, $\Sigma\cap B=\varnothing$.  \medskip
\item Definimos $f:\Sigma\cup B\to \Sigma^\star$ como 
\[
\ba{rlll}
f(s) & = & s & \mbox{si }s\in \Sigma \\ \\
f(s) & = & \varepsilon & \mbox{si }s\in B 
\ea
\] \medskip
\item $f$ induce un único homomorfismo $h:(\Sigma\cup B)^\star\to\Sigma^\star$ de tal forma que $h(x)= y$ si y sólo si $y$ se obtiene a partir de $x$ al borrar todos los símbolos de $B$. \medskip
\item A este homomorfismo lo denotamos con $erase_B$ \medskip
\item Ejemplo: Si $\Sigma=\{0,1\}$ y $B=\{(,\;)\}$ entonces $erase_B$ es el homomorfismo que borra paréntesis, por ejemplo:
\[
erase_B\Big( 00(11)(0)(01) \Big) = 0011001
\]
\ei
\end{frame}


\begin{frame}
  \titulos{Gramática de borrado a partir de $G$}{}
\bi
\item Sean $G=\pt{V,T,S,\mathcal{P}}$ una gramática libre de contexto y $R\subseteq T$
\item Definimos la gramática que borra a (símbolos de) $R$ en $G$, denotada $Er_R(G)$, como
\[
Er_R(G)= \pt{V,T-R,S,\mathcal{P}'}
\]
\item Donde $\mathcal{P}'$ se define como sigue:
\bi
\item Si $X\to v$ es una producción en $\mathcal{P}$, entonces $X\to erase_R(v)$ es una producción de $\mathcal{P}'$.
\ei
\item Si $G$ es una gramática libre de contexto y $R\subseteq T$, entonces
\[
L(Er_R(G))= erase_R[L(G)]
\]
\item Corolario: Si $L\subseteq \Sigma^\star$ es libre de contexto y $R\subseteq \Sigma$ entonces $erase_R[L]$ es libre de contexto.
% \item Es decir, el lenguaje de la gramática que borra a $R$ en $G$ coincide con la imagen de $L(G)$ bajo el homomorfismo que borra a $R$.
% %\item En particular $Er_R(G)$ es libre de contexto.
\ei
\end{frame}

\begin{frame}
  \titulos{Gramática separadora de $G$}{}
\bi
\item Sean $G=\pt{V,T,S,\mathcal{P}}$ una gramática libre de contexto en forma normal de Chomsky.
\item Definimos la gramática separadora de $G$, denotada $G_{sep}$ como
\[
G_{sep}= \pt{V,T\cup B,S,\mathcal{P}'}
\]
\item El conjunto de producciones $\mathcal{P}'$ se define como sigue:
\bi
\item Las producciones de $\mathcal{P}$ de la forma $A\to a$, están en $\mathcal{P}'$
\item Para cada producción en $\mathcal{P}$ de la forma $A_i\to B_iC_i$, $\mathcal{P}'$ tiene la siguiente producción
\[
A_i\to p_iB_i\bar{p_i}C_i
\]
\ei
\item Donde $B=\{p_1,\bar{p}_1,\ldots, p_n,\bar{p}_n\}$ es un conjunto de símbolos nuevos, i.e., $B\cap T=\varnothing$
\item $B$ es esencialmente un conjunto de $n$ juegos distintos de paréntesis.
\ei
\end{frame}



\begin{frame}
  \titulos{Gramática separadora}{Ejemplo}

\bi
\item Sea $G$ dada por
\[
S\to XY\;\;\;\;\;S\to YX\;\;\;\;\; Y\to ZZ\;\;\;\;\; 
X\to a\;\;\;\;\; Z\to a
\]
\item $G$ es ambigua:
\[
S\to XY\to aY \to aZZ \to aaZ \to aaa 
\]
\[
S\to YX\to ZZX \to aZX \to aaX \to aaa 
\]
\item $G_{sep}$ está dada por
\[
S\to (X)Y\;\;\;\;\;S\to [Y]X\;\;\;\;\; Y\to \{Z\}Z\;\;\;\;\; 
X\to a\;\;\;\;\; Z\to a
\]
\item $G_{sep}$ separa y codifica las dos derivaciones en $G$:
\[
S\to (X)Y\to (a)Y \to a\{Z\}Z \to (a)\{a\}Z \to (a)\{a\}a 
\]
\[
S\to [Y]X\to [\{Z\}Z]X \to [\{a\}Z]X \to [\{a\}a]X \to [\{a\}a]a 
\]
\ei
\end{frame}




\begin{frame}
  \titulos{Lenguajes de Dyck}{Lenguajes de paréntesis balanceados}
\bi
\item Sean $A$ un conjunto finito y $B_n=\{p_1,\bar{p}_1,\ldots,p_n,\bar{p}_n\}$ tal que $A\cap B_n=\varnothing$.
\item $B_n$ puede pensarse como un alfabeto con $n$ juegos de paréntesis distintos. Por ejemplo
  \begin{itemize}
  \item $B_1=\{(,\,)\}$
  \item $B_2=\{(,\,),\, [ ,\,]\}$
  \item $B_3=\{(,\,),\,[,\;],\,\{,\;\}\}$
  \end{itemize}
\item Con $D_n(A)$ denotamos al lenguaje de cadenas de $A\cup B_n$ generadas por la siguiente gramática libre de contexto

  \begin{itemize}
  \item Para toda $a\in A,\;S\to a$
    \item Para toda $p_i\in B_n,\;\;S\to p_iS\bar{p}_i$
  \item $S\to SS$
    \item $S\to \varepsilon$ 
  \end{itemize}
\ei
\end{frame}


\begin{frame}
\titulos{Lenguajes de Dyck}{Propiedades}
\bi
\item $D_n(A)$ se llama el lenguaje (generalizado) de Dyck de orden $n$.\medskip
\item $D_n(\varnothing)$ se llama el lenguaje (simple) de Dyck de orden $n$, denotado simplemente $D_n$.\medskip
\item Los lenguajes de Dyck tienen las siguientes propiedades:
  \begin{itemize}
  \item $A^\star\subseteq D_n(A)$\medskip
  \item Si $x,y\in D_n(A)$ entonces $xy\in D_n(A)$\medskip
  \item Si $x\in D_n(A)$ entonces $p_ix\bar{p}_i\in D_n(A)$\medskip
  \item Si $x\in D_n(A)$ y $x\notin A^\star$ entonces existen $u\in A^\star,\,v,w\in D_n(A),\,i\leq n$ tales que 
        $x=up_iv\bar{p}_iw$
  \end{itemize}
\ei
\end{frame}



\begin{frame}
  \titulos{La gramática $J$}{}
\bi
\item A partir de $G_{sep}=\pt{V,T\cup B,S,\mathcal{P}'}$ definimos ahora una gramática $J$ como sigue:\medskip
\item $J=\pt{V,T\cup B,S,\,\mathcal{P}''}$ donde $\mathcal{P}''$ consta de las siguientes producciones:
\bi
\item Todas las producciones $V\to a$ de  $\mathcal{P}'$\medskip %entonces $V\to a$ está en $\mathcal{P}''$
\item Si $A_i\to p_iB_i\bar{p_i}C_i$ está en $\mathcal{P}'$ entonces $\mathcal{P}''$ tiene a:
\bi
\item $A_i\to p_iB_i$\medskip
\item $V\to a\bar{p}_iC_i$, para cada producción $V\to a$ que esté en $\mathcal{P}'$
\ei
\ei
\item Es claro que $J$ es equivalente a una gramática lineal derecha.\medskip
\item Por lo tanto $L(J)$ es un lenguaje regular.
\ei
\end{frame}




\begin{frame}
  \titulos{Gramática $J$}{Ejemplo}
\bi
\item $G_{sep}$ está dada por
\[
S\to (X)Y\;\;\;\;\;S\to [Y]X\;\;\;\;\; Y\to \{Z\}Z\;\;\;\;\; 
X\to a\;\;\;\;\; Z\to a
\]
\item $J$ se construye como sigue:
\bi
\item $S\to (X)Y$ genera a : $S\to (X\;\;\;\;\;\;X\to a)Y\;\;\;\;\;\; Z\to a)Y$\medskip
\item $S\to [Y]X$ genera a : $S\to [Y\;\;\;\;\;\;X\to a]X\;\;\;\;\;\; Z\to a]X$\medskip
\item $Y\to \{Z\}Z$ genera a : $Y\to \{Z\;\;\;\;\;\;X\to a\}Z\;\;\;\;\;\; Z\to a\}Z$
\ei
\medskip
\item Así $J$ es:
\[
\ba{l}
S\to (X\;\;\;\;\;\;X\to a)Y\;\;\;\;\;\; Z\to a)Y \\ \\
S\to [Y\;\;\;\;\;\;X\to a]X\;\;\;\;\;\; Z\to a]X \\ \\
Y\to \{Z\;\;\;\;\;\;X\to a\}Z\;\;\;\;\;\; Z\to a\}Z \\ \\
X\to a\;\;\;\;\;\;Z\to a
\ea
\]
\ei
\end{frame}



\begin{frame}
  \titulos{Propiedades de $G_{sep}$}{}

  \begin{itemize}
  \item[P1] $erase_B[L(G_{sep})]= L(G)$\medskip
  \item[P2] $L(G_{sep})\subseteq D_n(T)$\medskip
  \item[P3] $L(G_{sep})\subseteq L(J)$\medskip
  \item[P4] $L(J)\cap D_n(T)\subseteq L(G_{sep})$\medskip
  \item[P5] Si $G$ está en FNC entonces existe $R$ regular tal que \[ L(G_{sep})=R\cap D_n(T) \]
   
  \end{itemize}
\end{frame}


% \begin{frame}
%   \titulos{Lenguajes de }{}
% \end{frame}

\begin{frame}
  \titulos{Teorema de Chomsky-Schuetzenberger}{}

Sea $L\subseteq T^\star$. Las siguientes condiciones son equivalentes:

\begin{enumerate}
\item[I)] $L$ es un lenguaje libre de contexto
\item[II)] Existen un lenguaje regular $R$, un homomorfismo $h$ y un número natural $n\in\mathbb{N}$ tales que
\[
L=h[R\cap D_n(T)]
\]
\end{enumerate}
\pause
Es decir, todo lenguaje libre de contexto es imagen homomórfica de la intersección de un lenguaje regular y un lenguaje de Dyck.
\end{frame}







\begin{frame}
  \titulos{Teorema de Chomsky-Schuetzenberger}{Versión usual}
\bi
\item El teorema de Chomsky-Schuetzenberger suele enunciarse y demostrarse utilizando lenguajes de Dyck simples como sigue:\medskip
%Sea $L\subseteq T^\star$. Las siguientes condiciones son equivalentes:
\item[] {\em Si $L$ es un lenguaje libre de contexto entonces existen un lenguaje regular $R$, un homomorfismo $h$ y un número natural $n>0$ tales que:}

 \[
 L=h[R\cap D_n]
 \]

% \begin{enumerate}
% \item[I)] $L$ es un lenguaje libre de contexto
% \item[II)] Existen un lenguaje regular $R$, un homomorfismo $h$ y un número natural $n\in\mathbb{N}$ tales que
% \[
% L=h[R\cap D_n(T)]
% \]
% \end{enumerate}
% Es decir, todo lenguaje libre de contexto es imagen homomórfica de la intersección de un lenguaje regular y un lenguaje de Dyck.
\medskip
\item Este teorema resulta equivalente a la versión aquí presentada.
\ei
\end{frame}








\begin{frame}
  \titulos{Reglas de producción}{Definición general}
\bi
\item El conjunto de reglas de producci\'on~$P$ de una gramática es un conjunto finito de 
pares $\pt{\al,\beta}$ tales que
\bi
 \item $\al\in (V\cup T)^\star - T^\star$. Es decir, $\al$ es una
  cadena de s\'imbolos terminales o no terminales, con al menos un
  s\'imbolo no-terminal.
 \item $\beta\in (V\cup T)^\star$. Es decir, $\beta$ es una cadena de
 s\'imbolos de $V\cup T$ , los cuales podr\'an ser todos terminales.
\ei

\item En lugar de escribir $\pt{\alpha,\beta}\in P$, escribimos $$\alpha \imp \beta$$ y
\item decimos que $\alpha$ \textbf{produce} a $\beta$, o que $\alpha$ se 
\textbf{reescribe} en $\beta$.
\ei
\end{frame}



\begin{frame}
\titulos{Gramáticas regulares o tipo 3}{Lenguajes regulares}
\bi
\item Son aquellas cuyas producciones son de una de las siguientes formas:
  \bi
  \item Lineal por la derecha: todas las producciones de la forma
    $$A\imp aB\;\;\;A\imp a\;\;\;A\imp\cv$$
    con $A,B\in V,\;a\in T$
  \item Lineal por la izquierda: todas las producciones de la forma
   $$A\imp Ba\;\;\;A\imp a\;\;\;A\imp\cv$$
    con $A,B\in V,\;a\in T$
  \item \textbf{No} se permite mezclar ambos tipos de producciones.
  \ei
\item Corresponden a autómatas finitos.
\ei
\end{frame}



\begin{frame}
  \titulos{$L=0^\star10^\star 10^\star$}{Ejemplos}
\bi
\item  $L$ es generado por:
  \beqs
 \ba{rll}
 S & \imp & A1A1A \\
 A & \imp & 0A\;|\;\cv
 \ea
\eeqs
\item  Esta gramática no es regular.
\item Pero el lenguaje $L$ sí lo es al existir una
gramática regular equivalente:
\beqs
 \ba{rll}
 S & \imp & 0S\;|\;1A \\
 A & \imp & 0A\;|\;1B \\
 B & \imp & 0B\;|\;\cv \\
 \ea
\eeqs
\ei
\end{frame}


\begin{frame}
 \titulos{Gramáticas libres de contexto o tipo 2}{Lenguajes libres del contexto} 
\bi
\item Son aquellas cuyas producciones son de la forma
$$\boxed{A\imp\al}$$
con $A\in V,\;\al\in(V\cup T)^\star$.
 
\item Esta definici\'on incluye a la regla $S\imp\cv$.
\item Las  gram\'aticas para lenguajes de programaci\'on caen en 
esta categor\'ia.
\item Corresponden a los autómatas de pila.
\ei
\end{frame}


\begin{frame}
  \titulos{Gramáticas dependientes del contexto o tipo 1}{Lenguajes dependientes del contexto}
\bi
\item  Tambi\'en llamados sensibles al contexto, son aquellos lenguajes generados 
  por gram\'aticas con todas sus producciones son de la forma
  $$\boxed{\alpha_1 A\alpha_2 \imp\alpha_1\beta\alpha_2}$$
  con $\alpha_1,\alpha_2\in(V\cup T)^\star,\;A\in V,\;\beta\neq\cv$, 
  adem\'as de que $|\alpha_1\beta\alpha_2| \geq |\alpha_1 A\alpha_2|$.
\item   Con la posible excepci\'on de la regla $S\imp\cv$, en cuyo caso se
  prohibe la presencia de $S$ a la derecha de las producciones.
  
 \item  Los aut\'omatas que reconocen este tipo de lenguajes son los llamados 
  aut\'omatas linealmente acotados.
\ei
\end{frame}

\begin{frame}
\titulos{Gramáticas dependientes del contexto}{Ejemplo}
\bi  
\item La siguiente gram\'atica dependiente del contexto 
  genera al lenguaje $$L=\{a^ib^ic^i\;|\;i\geq 0\}$$

\item[]
  \[
  \begin{array}{rclcrcl}
    S & \imp & A & \hspace*{20pt} & A& \imp & aABC \mid abC \\
    CB&\imp& BC & \hspace*{20pt} & bB&\imp & bb \\
    bC&\imp& bc & \hspace*{20pt} &cC&\imp& cc
  \end{array}
  \]
\item Se observa que $L$ no es un lenguaje libre de contexto.
\ei
\end{frame}


\begin{frame}
  \titulos{Gramáticas generales o tipo 0}{Lenguajes recursivamente enumerables}
\bi
\item Son aquellos lenguajes generados por una gram\'atica sin restricciones
  adicionales.
\item Tales gram\'aticas pueden incluir reglas de la forma
  $\qquad \boxed{\alpha\imp\cv}$
\item  De manera que la gram\'atica es capaz de borrar cadenas.
  Tales gram\'aticas se conocen como \textit{contra\'ibles}.  
\item 
  Por ejemplo: $$ aS\imp bSb,\; aSb\imp \cv,\; SbS\imp bcS $$
\item   Corresponden a  
  las m\'aquinas de Turing.
\ei
\end{frame}
\begin{frame}
\titulos{Gramáticas sin restricciones}{Ejemplo}
\bi
\item  La siguiente es una gram\'atica $G$ de tipo 0:
  \[
  \begin{array}{cccc}
   S\to AT & A\to 0AO & A\to 1AI & O0\to 0O \\
   O1\to 1O & I0\to 0I & I1\to1I & OT\to 0T\\
   IT\to 1T & A\to\cv & T\to\cv &
  \end{array}
  \]
\item $G$ es contraible debido a la presencia de $A\to\cv,\;T\to\cv$.
\item   $L(G)=\{ww\mid w\in\{0,1\}^\star\}$
\item Se observa que $L(G)$ es sensible al contexto pero esta gramática no lo es.
\item Existen lenguajes generales que no son sensibles al contexto. Por ejemplo:
\[
L=\{w\mid w\mbox{ codifica a una gramática dep. cont.} G \mbox{ y }w\notin L(G)\}
\]
\ei
\end{frame}


  \begin{frame}
    \titulos{Jerarquía de Chomsky}{Observaciones}
    \bi
    \item Decimos que un lenguaje es de tipo $i$ si y sólo si $i$ es el índice mas grande tal que existe una gramática de tipo $i$ que genera a $L$
% la gramática con
%       índice más mayor que lo genera es de tipo $i$.
      \item La jerarquía de gramáticas genera una jerarquía en los
        lenguajes generados:
        \beqs
        \alert{\mathcal{L}_3\subsetneq \mathcal{L}_2\subsetneq \mathcal{L}_1\subsetneq \mathcal{L}_0}
        \eeqs
        \item La jerarquía de Chomsky permite refinar la teoría de la
          computación clasificando lenguajes en función de los
          recursos computacionales necesarios para reconocerlos.
    \ei
    
  \end{frame}



% \bi
%  \item[Tipo 0] \textbf{Lenguajes recursivamente enumerables} \\
%   Son aquellos lenguajes generados por una gram\'atica sin restricciones
%   adicionales.\\
%   Tales gram\'aticas pueden incluir reglas de la forma
%   $\qquad \boxed{\alpha\imp\vacia}$
  
%   \vspace*{10pt}
  
%   De manera que la gram\'atica es capaz de borrar cadenas.
%   Tales gram\'aticas se conocen como \textit{contra\'ibles}.  
%   Por ejemplo: $$ aS\imp bSb,\; aSb\imp \cv,\; SbS\imp bcS $$

%   As\'i tambi\'en la siguiente es una gram\'atica de tipo 0 donde 
%   $L(G)=\{ww\mid w\in\{0,1\}^\star\}$
%   \[
%   \begin{array}{cccc}
%    S\to AT & A\to 0AO & A\to 1AI & O0\to 0O \\
%    O1\to 1O & I0\to 0I & I1\to1I & OT\to 0T\\
%    IT\to 1T & A\to\vacia & T\to\vacia &
%   \end{array}
%   \]

%   La idea del dise\~no de esta gram\'atica y la raz\'on del nombre 
%   \textit{recursivamente enumerable} se discutir\'an m\'as adelante.

%   Comentamos ahora que las m\'aquinas que aceptan este tipo de lenguajes son 
%   las M\'aquinas de Turing que tambi\'en ser\'an estudiadas m\'as adelante.


% \item[Tipo 1] \textbf{Lenguajes dependientes del contexto}\\
%   Tambi\'en llamados sensibles al contexto, son aquellos lenguajes generados 
%   por gram\'aticas con todas sus producciones son de la forma
%   $$\boxed{\alpha_1 A\alpha_2 \imp\alpha_1\beta\alpha_2}$$
%   con $\alpha_1,\alpha_2\in(V\cup T)^\star,\;A\in V,\;\beta\neq\vacia$, 
%   adem\'as de que $|\alpha_1\beta\alpha_2| \geq |\alpha_1 A\alpha_2|$.\\  
%   Con la posible excepci\'on de la regla $S\imp\vacia$, en cuyo caso se
%   prohibe la presencia de $S$ a la derecha de las producciones.
  
%   Los aut\'omatas que reconocen este tipo de lenguajes son los llamados 
%   aut\'omatas acotados linealmente.
  
%   Veamos un ejemplo, la siguiente gram\'atica dependiente del contexto 
%   genera al lenguaje $$L=\{a^ib^ic^i\;|\;i\geq 0\}$$
%   \[
%   \begin{array}{rclcrcl}
%     S & \imp & A & \hspace*{20pt} & A& \imp & aABC \mid abC \\
%     CB&\imp& BC & \hspace*{20pt} & bB&\imp & bb \\
%     bC&\imp& bc & \hspace*{20pt} &cC&\imp& cc
%   \end{array}
%   \]

% \newpage
  
% \item[Tipo 2] \textbf{Lenguajes libres del contexto} \\
% Son aquellos generados por gram\'aticas con todas sus producciones de la forma
% $$\boxed{A\imp\al}$$
% con $A\in V,\;\al\in(V\cup T)^\star$.
 
% Esta definici\'on incluye a la regla $S\imp\vacia$.
% La mayor\'ia de las gram\'aticas para lenguajes de programaci\'on caen en 
% esta categor\'ia.
% As\'i mismo las m\'aquinas que aceptan este tipo de lenguajes son los llamados 
% aut\'omatas de pila que ser\'an estudiados en el siguiente tema.
         


  
% \ei




\end{document}


